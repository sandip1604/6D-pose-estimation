{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "# 6D Pose Object Detector and Refiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "6D pose estimation of an object is a ubiquitous problem in Robotics. We can find its applications in Pick and Place, Service robotics, autonomous driving, etc. The program below is our attempt to solve the problem using deep learning, in tandem to image processing algorithms like Point n perspective and RANSAC. We are using LineMOD dataset for training and testing. LineMOD dataset has various images of cluttered images of the objects saperated in various classes. The images are accompanied by the true 6D poses in rotation and translation, 3D meshes and point cloud data for the class.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda create --name 6POD --file requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Helper import *\n",
    "from ground_truth import create_GT_masks\n",
    "from UV_mapping import create_UV_XYZ_dictionary\n",
    "from LineMOD import LineMODDataset\n",
    "from PoseRefinement import *\n",
    "from Correspondence import *\n",
    "from Pose_estimation import *\n",
    "from Test import test\n",
    "import argparse\n",
    "\n",
    "np.random.seed(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Download\n",
    "\n",
    "The dataset is downloaded for the first time when the program is executed. The download links for each class in accompanied in dataset_install.txt. User can include additional classes to what we have used by altering this file. For our purposes we have used 15 classes of objects. The test-train split can be changed by varying the default 0.2 setting in the argument parser. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(\"LineMOD_Dataset\")\n",
    "    file1 = open('dataset_install.txt', 'r') \n",
    "    Lines = file1.readlines()\n",
    "    for url in Lines[:-1]:\n",
    "        zipresp = urlopen(url)\n",
    "        tempzip = open(\"tempfile.zip\", \"wb\")\n",
    "        tempzip.write(zipresp.read())\n",
    "        tempzip.close()\n",
    "\n",
    "        zf = ZipFile(\"tempfile.zip\")\n",
    "        zf.extractall(path = 'LineMOD_Dataset')\n",
    "        zf.close()\n",
    "        \n",
    "    zipresp = urlopen(Lines[-1])\n",
    "    tempzip = open(\"tempfile.zip\", \"wb\")\n",
    "    tempzip.write(zipresp.read())\n",
    "    tempzip.close()\n",
    "\n",
    "    zf = ZipFile(\"tempfile.zip\")\n",
    "    zf.extractall()\n",
    "    zf.close()\n",
    "except FileExistsError:\n",
    "    print(\"Data set exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Script to create the Ground Truth masks')\n",
    "parser.add_argument(\"--root_dir\", default=\"LineMOD_Dataset/\",\n",
    "                    help=\"path to dataset directory\")\n",
    "\n",
    "parser.add_argument(\"--bgd_dir\", default=\"val2017/\",\n",
    "                    help=\"path to background images dataset directory\")\n",
    "parser.add_argument(\"--split\", default=0.20, help=\"train:test split ratio\")\n",
    "\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = args.root_dir\n",
    "background_dir = args.bgd_dir\n",
    "\n",
    "imageList = []\n",
    "for root, dirs, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\"):  # images that exist\n",
    "            imageList.append(os.path.join(root, file))\n",
    "\n",
    "nImages = len(imageList)\n",
    "ind = list(range(nImages))\n",
    "\n",
    "np.random.shuffle(ind)\n",
    "\n",
    "split = int(args.split * nImages)\n",
    "trainInd, testInd = ind[:split], ind[split:]\n",
    "print(\"Training Samples:\", len(trainInd))\n",
    "print(\"Testing Samples:\", len(testInd))\n",
    "\n",
    "save_obj(imageList, root_dir + \"all_images_adr\")\n",
    "save_obj(trainInd, root_dir + \"train_images_indices\")\n",
    "save_obj(testInd, root_dir + \"test_images_indices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {'ape': 1, \n",
    "           'phone':2, \n",
    "           'cam': 3, \n",
    "           'duck': 4,\n",
    "           'can': 5, \n",
    "           'cat': 6, \n",
    "           'driller': 7,\n",
    "           'iron': 8, \n",
    "           'eggbox': 9, \n",
    "           'glue': 10, \n",
    "           'holepuncher': 11, \n",
    "           'benchviseblue': 12, \n",
    "           'lamp': 13 \n",
    "           }\n",
    "class_names = list(classes.keys())\n",
    "dataset_dir_structure(root_dir, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory Structure\n",
    "After executing the above blocks, directory structure of the LineMOD_dataset should look somethink the tree below. A saperate directory for masks, pose predictions, refinement, eyc. The processes described below are time consuming thus the caches are made for debugging purposes as well as saving the progress."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "LineMOD_dataset\n",
    "├── all_images_adr.pkl\n",
    "├── ape\n",
    "│   ├── OLDmesh.ply\n",
    "│   ├── UV-XYZ_mapping.pkl\n",
    "│   ├── data\n",
    "│   ├── distance.txt\n",
    "│   ├── ground_truth\n",
    "│   ├── mesh.ply\n",
    "│   ├── object.xyz\n",
    "│   ├── pose_refinement\n",
    "│   ├── predicted_pose\n",
    "│   └── transform.dat\n",
    "├── benchviseblue\n",
    "│   ├── OLDmesh.ply\n",
    "│   ├── UV-XYZ_mapping.pkl\n",
    "│   ├── data\n",
    "│   ├── distance.txt\n",
    "│   ├── ground_truth\n",
    "│   ├── mesh.ply\n",
    "│   ├── object.xyz\n",
    "│   ├── pose_refinement\n",
    "│   ├── predicted_pose\n",
    "│   └── transform.dat\n",
    "'''\n",
    "├── lamp\n",
    "│   ├── OLDmesh.ply\n",
    "│   ├── UV-XYZ_mapping.pkl\n",
    "│   ├── data\n",
    "│   ├── distance.txt\n",
    "│   ├── ground_truth\n",
    "│   ├── mesh.ply\n",
    "│   ├── object.xyz\n",
    "│   ├── pose_refinement\n",
    "│   ├── predicted_pose\n",
    "│   └── transform.dat\n",
    "├── phone\n",
    "│   ├── UV-XYZ_mapping.pkl\n",
    "│   ├── data\n",
    "│   ├── distance.txt\n",
    "│   ├── ground_truth\n",
    "│   ├── mesh.ply\n",
    "│   ├── object.xyz\n",
    "│   ├── oldmesh.ply\n",
    "│   ├── pose_refinement\n",
    "│   ├── predicted_pose\n",
    "│   └── transform.dat\n",
    "├── test_images_indices.pkl\n",
    "└── train_images_indices.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx = 572.41140\n",
    "px = 325.26110\n",
    "fy = 573.57043\n",
    "py = 242.04899\n",
    "\n",
    "intrinsicCameraMatrix = np.zeros((3, 3))\n",
    "intrinsicCameraMatrix[0, 0] = fx\n",
    "intrinsicCameraMatrix[0, 2] = px\n",
    "intrinsicCameraMatrix[1, 1] = fy\n",
    "intrinsicCameraMatrix[1, 2] = py\n",
    "intrinsicCameraMatrix[2, 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===================Creating Ground Truth Masks=========================\")\n",
    "create_GT_masks(background_dir, root_dir, classes, intrinsicCameraMatrix)\n",
    "print(\"====================Creating UV Dictionary=============================\")\n",
    "create_UV_XYZ_dictionary(root_dir)\n",
    "print(\"Done\")\n",
    "print(\"===========================Finished====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------ Started training of the correspondence block ------\")\n",
    "torch.cuda.empty_cache()\n",
    "train_correspondence_block(root_dir, classes, numEpoch=5, batchSize=5, validationSplit = 0.2)\n",
    "print(\"==================== Training Finished ===================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After each epoch the validation loss is compared with the one with previously minimum validation error and the model is saved if there is improvement in the loss. This saves the model from over-training and saves the progress in case of disruption during training. The model is saved by the name \"correspondance_block.pt\" after the original nomenclature used by the author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"========== Pose Estimation Started ==========\")\n",
    "torch.cuda.empty_cache()\n",
    "initial_pose_estimation(root_dir, classes, intrinsicCameraMatrix)\n",
    "print(\"========== Pose Estimation Finished =========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=========== Pose Refinement Started ===========\")\n",
    "create_refinement_inputs(root_dir, classes, intrinsicCameraMatrix)\n",
    "train_pose_refinement(root_dir, classes, epochs=3)\n",
    "print(\"======== Pose Refinement Finished =============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classScore, classInst = test(50, intrinsicCameraMatrix, classes)\n",
    "classPerformance = {}\n",
    "for key in classScore:\n",
    "    classPerformance[key] = classScore[key]/classInst[key]\n",
    "\n",
    "print(classPerformance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
